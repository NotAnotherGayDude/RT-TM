/*
Copyright (c) 2025 RealTimeChris (Chris M.)

This file is part of software offered under a restricted-use license to a designated Licensee,
whose identity is confirmed in writing by the Author.

License Terms (Summary):
- Exclusive, non-transferable license for internal use only.
- Redistribution, sublicensing, or public disclosure is prohibited without written consent.
- Full ownership remains with the Author.
- License may terminate if unused for [X months], if materially breached, or by mutual agreement.
- No warranty is provided, express or implied.

Full license terms are provided in the LICENSE file distributed with this software.

Signed,
RealTimeChris (Chris M.)
2025
*/

#pragma once

#include <rt_tm/common/model.hpp>
#include <rt_tm/common/model_parser.hpp>
#include <rt_tm/common/common.hpp>
#include <cstdint>

namespace rt_tm {

	struct harbinger {
		RT_TM_FORCE_INLINE static consteval auto generate_model_config(auto model_generation, auto model_size, kernel_type_profile kernel_profile, model_arch arch,
			bool exceptions = false, kv_cache_strategy cache_strategy = kv_cache_strategy::paged, bool use_gradient_checkpointing = false,
			rope_scaling_type rope_scaling = rope_scaling_type::linear, bool use_rotary_embeddings = true, uint64_t kv_cache_block_size = 16, bool use_flash_attention = true,
			norm_type rms_norm_type = norm_type::rms_standard, model_format format = model_format::gguf, float norm_epsilon = 1e-6f) {
			model_config<decltype(model_generation), decltype(model_size)> config{ model_generation, model_size, kernel_profile, arch, exceptions, cache_strategy,
				use_gradient_checkpointing, rope_scaling, use_rotary_embeddings, kv_cache_block_size, use_flash_attention, rms_norm_type, format, norm_epsilon };
			return config;
		};

		template<model_config config> RT_TM_FORCE_INLINE static auto parse_model_graph(std::string_view path) {
			using model_type = model<config>;
			using base_type	 = model_type::base_type;
			std::unique_ptr<base_type> return_value{};
			model_type* new_model{ new model_type{ path } };
			return_value.reset(new_model);
			return return_value;
		}

		RT_TM_FORCE_INLINE static cli_params parse_cli_arguments(uint32_t argc, char** argv) {
			std::vector<std::string> cli_args{};
			for (size_t x = 0; x < argc; ++x) {
				cli_args.emplace_back(argv[x]);
			}
			return rt_tm::harbinger::parse_cli_arguments(cli_args);
		}


		RT_TM_FORCE_INLINE static cli_params parse_cli_arguments(const std::vector<std::string>& command_line) {
			cli_params result{};
			std::string current_flag{};
			bool expect_value = false;

			for (const auto& token: command_line) {
				if (token.empty())
					continue;

				if (token[0] == '-') {
					current_flag = token;
					if (token == "-m" || token == "-t" || token == "-p" || token == "-s" || token == "-n" || token == "-b") {
						expect_value = true;
					} else {
						expect_value = false;
					}
				} else if (expect_value) {
					if (current_flag == "-m") {
						result.model_file = token;
					} else if (current_flag == "-t") {
						try {
							result.thread_count = std::stoull(token);
						} catch (const std::exception&) {
							result.thread_count = 1;
						}
					} else if (current_flag == "-p") {
						result.prompt = token;
					} else if (current_flag == "-s") {
						try {
							result.seed = std::stoull(token);
						} catch (const std::exception&) {
							result.seed = 0;
						}
					} else if (current_flag == "-n") {
						try {
							result.n_predict = std::stoull(token);
						} catch (const std::exception&) {
							result.n_predict = 128;
						}
					} else if (current_flag == "-b") {
						try {
							result.batch_size = std::stoull(token);
						} catch (const std::exception&) {
							result.batch_size = 512;
						}
					}
					expect_value = false;
				}
			}

			return result;
		}
	};

}
